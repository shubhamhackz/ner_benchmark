{
    "cells": [
        {
            "cell_type": "raw",
            "metadata": {
                "vscode": {
                    "languageId": "raw"
                }
            },
            "source": [
                "# üöÄ GLiNER vs OpenAI NER Benchmark\n",
                "\n",
                "**Clean, focused comparison between GLiNER Large and OpenAI GPT-4o-mini for Named Entity Recognition on business card data.**\n",
                "\n",
                "## Features:\n",
                "- ‚úÖ GLiNER Large model (free, local)\n",
                "- ‚úÖ OpenAI GPT-4o-mini comparison (optional)\n",
                "- ‚úÖ Configurable dataset size (50-1000 samples)\n",
                "- ‚úÖ Business card entity extraction (Person, Email, Phone, Organization)\n",
                "- ‚úÖ Comprehensive performance analysis\n",
                "\n",
                "## Quick Start:\n",
                "1. Run all cells in order\n",
                "2. Choose GLiNER-only (FREE) or vs OpenAI\n",
                "3. Select dataset size (50-1000)\n",
                "4. Get comprehensive results!\n",
                "\n",
                "---\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# üì¶ Import Required Libraries\n",
                "import json\n",
                "import time\n",
                "import random\n",
                "import re\n",
                "import os\n",
                "from typing import List, Dict, Tuple, Any\n",
                "from dataclasses import dataclass, asdict\n",
                "from collections import defaultdict, Counter\n",
                "from datetime import datetime\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Set random seed for reproducibility\n",
                "random.seed(42)\n",
                "np.random.seed(42)\n",
                "\n",
                "print(\"üì¶ All libraries imported successfully!\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ‚öôÔ∏è Configuration\n",
                "print(\"üöÄ GLiNER vs OpenAI NER Benchmark Configuration\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "# Choose benchmark mode\n",
                "print(\"\\nü§ñ Available benchmark modes:\")\n",
                "print(\"1. üÜì GLiNER Large only (FREE - no API key required)\")\n",
                "print(\"2. üî• GLiNER Large vs OpenAI (requires API key)\")\n",
                "\n",
                "choice = input(\"\\nChoose your mode (1-2, default=1): \").strip() or \"1\"\n",
                "\n",
                "if choice == \"2\":\n",
                "    RUN_OPENAI = True\n",
                "    print(\"‚úÖ Selected: GLiNER Large vs OpenAI comparison\")\n",
                "else:\n",
                "    RUN_OPENAI = False\n",
                "    print(\"‚úÖ Selected: GLiNER Large only (FREE mode)\")\n",
                "\n",
                "# Sample size configuration\n",
                "while True:\n",
                "    try:\n",
                "        SAMPLE_SIZE = int(input(\"\\nüìä How many samples to test? (50-1000, default 100): \") or \"100\")\n",
                "        if 50 <= SAMPLE_SIZE <= 1000:\n",
                "            break\n",
                "        else:\n",
                "            print(\"‚ö†Ô∏è Please enter a number between 50 and 1000\")\n",
                "    except ValueError:\n",
                "        print(\"‚ö†Ô∏è Please enter a valid number\")\n",
                "\n",
                "# Performance tier guidance\n",
                "if SAMPLE_SIZE <= 100:\n",
                "    print(\"üîç Quick Test Mode: Fast evaluation for initial testing\")\n",
                "elif SAMPLE_SIZE <= 500:\n",
                "    print(\"üìä Standard Evaluation: Balanced performance assessment\")\n",
                "else:\n",
                "    print(\"üèÜ Comprehensive Benchmark: Full production-grade evaluation\")\n",
                "\n",
                "# Get OpenAI API key if needed\n",
                "if RUN_OPENAI:\n",
                "    print(f\"\\nüí∞ Note: OpenAI comparison will use API calls (small cost)\")\n",
                "    import getpass\n",
                "    try:\n",
                "        OPENAI_API_KEY = getpass.getpass(\"üîë Enter your OpenAI API key: \")\n",
                "        if not OPENAI_API_KEY.strip():\n",
                "            print(\"‚ùå No API key provided. Switching to GLiNER-only mode.\")\n",
                "            RUN_OPENAI = False\n",
                "        else:\n",
                "            os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY.strip()\n",
                "            print(\"‚úÖ OpenAI API key set successfully!\")\n",
                "    except Exception as e:\n",
                "        print(f\"‚ùå OpenAI initialization failed: {e}\")\n",
                "        print(\"üîÑ Falling back to GLiNER-only mode...\")\n",
                "        RUN_OPENAI = False\n",
                "\n",
                "# Entity labels for business card NER\n",
                "ENTITY_LABELS = [\"person\", \"email\", \"phone\", \"organization\"]\n",
                "\n",
                "print(f\"\\nüéØ FINAL CONFIGURATION:\")\n",
                "print(f\"   üìä Sample size: {SAMPLE_SIZE}\")\n",
                "print(f\"   ü§ñ GLiNER Large: ‚úÖ Enabled\")\n",
                "print(f\"   üî• OpenAI: {'‚úÖ Enabled' if RUN_OPENAI else '‚ùå Disabled'}\")\n",
                "print(f\"   üè∑Ô∏è Entities: {', '.join(ENTITY_LABELS)}\")\n",
                "print(\"=\" * 60)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# üèóÔ∏è Data Structures\n",
                "@dataclass\n",
                "class GroundTruth:\n",
                "    name: str\n",
                "    company: str\n",
                "    email: str\n",
                "    phone: str\n",
                "\n",
                "@dataclass\n",
                "class BusinessCardSample:\n",
                "    sample_id: int\n",
                "    scenario: str\n",
                "    ocr_lines: List[str]\n",
                "    ground_truth: GroundTruth\n",
                "\n",
                "@dataclass\n",
                "class BenchmarkResult:\n",
                "    sample_id: int\n",
                "    scenario: str\n",
                "    gliner_accuracy: Dict[str, float]\n",
                "    openai_accuracy: Dict[str, float]\n",
                "    gliner_time: float\n",
                "    openai_time: float\n",
                "\n",
                "print(\"üèóÔ∏è Data structures defined successfully!\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# üé≤ Synthetic Business Card Data Generator\n",
                "class BusinessCardGenerator:\n",
                "    def __init__(self):\n",
                "        self.names = [\n",
                "            \"John Smith\", \"Sarah Johnson\", \"Michael Brown\", \"Emily Davis\", \"David Wilson\",\n",
                "            \"Lisa Anderson\", \"Robert Taylor\", \"Jennifer Martinez\", \"William Garcia\", \"Maria Rodriguez\"\n",
                "        ]\n",
                "        \n",
                "        self.companies = [\n",
                "            \"TechCorp Solutions\", \"Global Dynamics Inc\", \"Innovation Labs\", \"Digital Ventures\",\n",
                "            \"Future Systems\", \"Smart Technologies\", \"Advanced Analytics\", \"Cloud Solutions\"\n",
                "        ]\n",
                "        \n",
                "        self.domains = [\"gmail.com\", \"company.com\", \"business.org\", \"corp.net\", \"tech.io\"]\n",
                "    \n",
                "    def generate_phone(self):\n",
                "        return f\"+1-{random.randint(200,999)}-{random.randint(200,999)}-{random.randint(1000,9999)}\"\n",
                "    \n",
                "    def create_clean_sample(self, sample_id: int) -> BusinessCardSample:\n",
                "        name = random.choice(self.names)\n",
                "        company = random.choice(self.companies)\n",
                "        email = f\"{name.lower().replace(' ', '.')}.{random.choice(self.domains)}\"\n",
                "        phone = self.generate_phone()\n",
                "        \n",
                "        ocr_lines = [\n",
                "            name,\n",
                "            \"Senior Manager\",\n",
                "            company,\n",
                "            email,\n",
                "            phone,\n",
                "            \"www.company.com\"\n",
                "        ]\n",
                "        \n",
                "        return BusinessCardSample(\n",
                "            sample_id=sample_id,\n",
                "            scenario=\"clean\",\n",
                "            ocr_lines=ocr_lines,\n",
                "            ground_truth=GroundTruth(name=name, company=company, email=email, phone=phone)\n",
                "        )\n",
                "    \n",
                "    def create_noisy_sample(self, sample_id: int) -> BusinessCardSample:\n",
                "        clean_sample = self.create_clean_sample(sample_id)\n",
                "        \n",
                "        # Add OCR noise\n",
                "        noisy_lines = []\n",
                "        for line in clean_sample.ocr_lines:\n",
                "            if random.random() < 0.3:  # 30% chance of noise\n",
                "                line = line.replace('o', '0').replace('l', '1').replace('S', '5')\n",
                "            noisy_lines.append(line)\n",
                "        \n",
                "        clean_sample.ocr_lines = noisy_lines\n",
                "        clean_sample.scenario = \"noisy\"\n",
                "        return clean_sample\n",
                "    \n",
                "    def generate_dataset(self, size: int) -> List[BusinessCardSample]:\n",
                "        dataset = []\n",
                "        for i in range(size):\n",
                "            if random.random() < 0.7:  # 70% clean, 30% noisy\n",
                "                sample = self.create_clean_sample(i)\n",
                "            else:\n",
                "                sample = self.create_noisy_sample(i)\n",
                "            dataset.append(sample)\n",
                "        return dataset\n",
                "\n",
                "generator = BusinessCardGenerator()\n",
                "print(\"üé≤ Business card data generator ready!\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# üì¶ Install Required Packages\n",
                "print(\"üì¶ Installing required packages...\")\n",
                "\n",
                "# Check if we're in Colab\n",
                "try:\n",
                "    import google.colab\n",
                "    IN_COLAB = True\n",
                "    print(\"üìç Running in Google Colab\")\n",
                "    \n",
                "    # Install packages in Colab\n",
                "    import subprocess\n",
                "    import sys\n",
                "    \n",
                "    def install_package(package):\n",
                "        print(f\"üîß Installing {package}...\")\n",
                "        try:\n",
                "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package, \"--quiet\"])\n",
                "            print(f\"‚úÖ {package} installed successfully!\")\n",
                "            return True\n",
                "        except subprocess.CalledProcessError as e:\n",
                "            print(f\"‚ùå Failed to install {package}: {e}\")\n",
                "            return False\n",
                "    \n",
                "    # Install required packages\n",
                "    packages = [\n",
                "        \"torch\",  # PyTorch for GLiNER\n",
                "        \"gliner\",  # GLiNER model\n",
                "        \"openai\",  # OpenAI API (optional)\n",
                "        \"transformers\",  # For model loading\n",
                "        \"accelerate\"  # For GPU optimization\n",
                "    ]\n",
                "    \n",
                "    success_count = 0\n",
                "    for package in packages:\n",
                "        if install_package(package):\n",
                "            success_count += 1\n",
                "    \n",
                "    print(f\"\\nüéØ Installation Summary: {success_count}/{len(packages)} packages installed\")\n",
                "    \n",
                "    if success_count == len(packages):\n",
                "        print(\"‚úÖ All packages installed successfully!\")\n",
                "    else:\n",
                "        print(\"‚ö†Ô∏è Some packages failed to install - continuing anyway...\")\n",
                "        \n",
                "except ImportError:\n",
                "    print(\"üìç Running locally\")\n",
                "    print(\"üí° Please ensure you have installed the required packages:\")\n",
                "    print(\"   pip install torch gliner openai transformers accelerate\")\n",
                "    print(\"üìã Checking if packages are available...\")\n",
                "    \n",
                "    # Check local packages\n",
                "    missing_packages = []\n",
                "    try:\n",
                "        import torch\n",
                "        print(\"‚úÖ PyTorch available\")\n",
                "    except ImportError:\n",
                "        missing_packages.append(\"torch\")\n",
                "        print(\"‚ùå PyTorch missing\")\n",
                "    \n",
                "    try:\n",
                "        import gliner\n",
                "        print(\"‚úÖ GLiNER available\")\n",
                "    except ImportError:\n",
                "        missing_packages.append(\"gliner\")\n",
                "        print(\"‚ùå GLiNER missing\")\n",
                "    \n",
                "    try:\n",
                "        import openai\n",
                "        print(\"‚úÖ OpenAI available\")\n",
                "    except ImportError:\n",
                "        missing_packages.append(\"openai\")\n",
                "        print(\"‚ö†Ô∏è OpenAI missing (optional for comparison mode)\")\n",
                "    \n",
                "    if missing_packages:\n",
                "        print(f\"\\n‚ö†Ô∏è Missing packages: {', '.join(missing_packages)}\")\n",
                "        print(\"üì• Install with: pip install \" + \" \".join(missing_packages))\n",
                "    else:\n",
                "        print(\"\\n‚úÖ All required packages are available!\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"üöÄ Ready to proceed with GLiNER setup!\")\n",
                "print(\"=\"*60)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ü§ñ GLiNER Setup\n",
                "print(\"ü§ñ Setting up GLiNER Large model...\")\n",
                "\n",
                "try:\n",
                "    import torch\n",
                "    from gliner import GLiNER\n",
                "    \n",
                "    # Check for GPU\n",
                "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "    print(f\"üîß Device: {DEVICE}\")\n",
                "    \n",
                "    if torch.cuda.is_available():\n",
                "        gpu_name = torch.cuda.get_device_name(0)\n",
                "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
                "        print(f\"üöÄ GPU: {gpu_name} ({gpu_memory:.1f} GB)\")\n",
                "    \n",
                "    # Load GLiNER Large model\n",
                "    print(\"üì• Loading GLiNER Large model...\")\n",
                "    gliner_model = GLiNER.from_pretrained(\"urchade/gliner_large-v2.1\")\n",
                "    gliner_model.to(DEVICE)\n",
                "    gliner_model.eval()\n",
                "    \n",
                "    print(\"‚úÖ GLiNER Large model loaded successfully!\")\n",
                "    \n",
                "    if torch.cuda.is_available():\n",
                "        torch.cuda.empty_cache()\n",
                "        memory_used = torch.cuda.memory_allocated(0) / 1024**3\n",
                "        print(f\"üìä GPU memory used: {memory_used:.2f} GB\")\n",
                "        \n",
                "except Exception as e:\n",
                "    print(f\"‚ùå GLiNER setup failed: {e}\")\n",
                "    print(\"üí° Install with: pip install gliner torch\")\n",
                "    print(\"üí° For Colab: !pip install gliner torch\")\n",
                "    raise\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# üß† NER Benchmark Class\n",
                "class NERBenchmark:\n",
                "    def __init__(self):\n",
                "        self.entity_labels = ENTITY_LABELS\n",
                "        self.device = DEVICE\n",
                "        \n",
                "        # Initialize OpenAI client if needed\n",
                "        if RUN_OPENAI:\n",
                "            try:\n",
                "                from openai import OpenAI\n",
                "                self.openai_client = OpenAI()\n",
                "                print(\"‚úÖ OpenAI client initialized\")\n",
                "            except Exception as e:\n",
                "                print(f\"‚ùå OpenAI initialization failed: {e}\")\n",
                "                self.openai_client = None\n",
                "    \n",
                "    def extract_with_gliner(self, text: str) -> Tuple[Dict[str, List[str]], float]:\n",
                "        start_time = time.time()\n",
                "        \n",
                "        try:\n",
                "            # Enhanced labels for better person detection\n",
                "            enhanced_labels = {\n",
                "                \"person\": [\"person\", \"name\", \"individual\", \"contact name\", \"full name\"],\n",
                "                \"email\": [\"email\", \"email address\"],\n",
                "                \"phone\": [\"phone\", \"telephone\", \"phone number\"],\n",
                "                \"organization\": [\"organization\", \"company\", \"business\"]\n",
                "            }\n",
                "            \n",
                "            results = {label: [] for label in self.entity_labels}\n",
                "            \n",
                "            for entity_type, labels in enhanced_labels.items():\n",
                "                entities = gliner_model.predict_entities(text, labels)\n",
                "                for entity in entities:\n",
                "                    results[entity_type].append(entity[\"text\"])\n",
                "            \n",
                "            # Remove duplicates\n",
                "            for key in results:\n",
                "                results[key] = list(set(results[key]))\n",
                "                \n",
                "        except Exception as e:\n",
                "            print(f\"GLiNER error: {e}\")\n",
                "            results = {label: [] for label in self.entity_labels}\n",
                "        \n",
                "        elapsed_time = time.time() - start_time\n",
                "        return results, elapsed_time\n",
                "    \n",
                "    def extract_with_openai(self, text: str) -> Tuple[Dict[str, List[str]], float]:\n",
                "        if not self.openai_client:\n",
                "            return {label: [] for label in self.entity_labels}, 0.0\n",
                "        \n",
                "        start_time = time.time()\n",
                "        \n",
                "        prompt = f\"\"\"Extract named entities from this business card text. Return ONLY a JSON object with these exact keys: person, email, phone, organization. Each value should be a list of strings.\n",
                "\n",
                "Text: {text}\n",
                "\n",
                "JSON:\"\"\"\n",
                "        \n",
                "        try:\n",
                "            response = self.openai_client.chat.completions.create(\n",
                "                model=\"gpt-4o-mini\",\n",
                "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
                "                temperature=0,\n",
                "                max_tokens=200\n",
                "            )\n",
                "            \n",
                "            result_text = response.choices[0].message.content.strip()\n",
                "            if result_text.startswith(\"```json\"):\n",
                "                result_text = result_text[7:-3]\n",
                "            elif result_text.startswith(\"```\"):\n",
                "                result_text = result_text[3:-3]\n",
                "            \n",
                "            results = json.loads(result_text.strip())\n",
                "            \n",
                "        except Exception as e:\n",
                "            print(f\"OpenAI error: {e}\")\n",
                "            results = {label: [] for label in self.entity_labels}\n",
                "        \n",
                "        elapsed_time = time.time() - start_time\n",
                "        return results, elapsed_time\n",
                "    \n",
                "    def calculate_accuracy(self, predictions: Dict[str, List[str]], ground_truth: GroundTruth) -> Dict[str, float]:\n",
                "        gt_map = {\n",
                "            \"person\": ground_truth.name,\n",
                "            \"email\": ground_truth.email,\n",
                "            \"phone\": ground_truth.phone,\n",
                "            \"organization\": ground_truth.company\n",
                "        }\n",
                "        \n",
                "        accuracy = {}\n",
                "        for entity_type in self.entity_labels:\n",
                "            predicted = predictions.get(entity_type, [])\n",
                "            expected = gt_map[entity_type]\n",
                "            \n",
                "            if not predicted:\n",
                "                accuracy[entity_type] = 0.0\n",
                "            else:\n",
                "                # Check if any prediction matches (partial match for flexibility)\n",
                "                matches = any(expected.lower() in pred.lower() or pred.lower() in expected.lower() \n",
                "                            for pred in predicted)\n",
                "                accuracy[entity_type] = 1.0 if matches else 0.0\n",
                "        \n",
                "        return accuracy\n",
                "\n",
                "benchmark = NERBenchmark()\n",
                "print(\"üß† NER Benchmark class initialized!\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# üîÑ Pull Latest Changes from GitHub (Colab Setup)\n",
                "import os\n",
                "import subprocess\n",
                "\n",
                "def run_command(cmd):\n",
                "    \"\"\"Run shell command and return output\"\"\"\n",
                "    try:\n",
                "        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
                "        return result.returncode == 0, result.stdout, result.stderr\n",
                "    except Exception as e:\n",
                "        return False, \"\", str(e)\n",
                "\n",
                "print(\"üöÄ Setting up latest version from GitHub...\")\n",
                "\n",
                "# Repository details\n",
                "REPO_URL = \"https://github.com/shubhamhackz/ner_benchmark.git\"\n",
                "REPO_NAME = \"ner_benchmark\"\n",
                "\n",
                "# Check if we're in Colab\n",
                "try:\n",
                "    import google.colab\n",
                "    IN_COLAB = True\n",
                "    print(\"üìç Running in Google Colab\")\n",
                "except ImportError:\n",
                "    IN_COLAB = False\n",
                "    print(\"üìç Running locally\")\n",
                "\n",
                "if IN_COLAB:\n",
                "    # Change to content directory in Colab\n",
                "    os.chdir('/content')\n",
                "    \n",
                "    # Check if repository already exists\n",
                "    if os.path.exists(REPO_NAME):\n",
                "        print(f\"üìÇ Repository '{REPO_NAME}' found - pulling latest changes...\")\n",
                "        os.chdir(REPO_NAME)\n",
                "        \n",
                "        # Pull latest changes\n",
                "        success, stdout, stderr = run_command(\"git pull origin main\")\n",
                "        if success:\n",
                "            print(\"‚úÖ Successfully pulled latest changes!\")\n",
                "            if stdout.strip():\n",
                "                print(f\"üìÑ Git output: {stdout.strip()}\")\n",
                "        else:\n",
                "            print(f\"‚ö†Ô∏è Pull failed: {stderr}\")\n",
                "            print(\"üîÑ Trying to reset and pull again...\")\n",
                "            run_command(\"git reset --hard HEAD\")\n",
                "            success, stdout, stderr = run_command(\"git pull origin main\")\n",
                "            if success:\n",
                "                print(\"‚úÖ Successfully pulled after reset!\")\n",
                "            else:\n",
                "                print(f\"‚ùå Still failed: {stderr}\")\n",
                "    else:\n",
                "        print(f\"üì• Cloning repository '{REPO_NAME}'...\")\n",
                "        success, stdout, stderr = run_command(f\"git clone {REPO_URL}\")\n",
                "        if success:\n",
                "            print(\"‚úÖ Successfully cloned repository!\")\n",
                "            os.chdir(REPO_NAME)\n",
                "        else:\n",
                "            print(f\"‚ùå Clone failed: {stderr}\")\n",
                "    \n",
                "    # Show current status\n",
                "    if os.path.exists('.git'):\n",
                "        success, commit_hash, _ = run_command(\"git rev-parse --short HEAD\")\n",
                "        success2, branch, _ = run_command(\"git rev-parse --abbrev-ref HEAD\")\n",
                "        \n",
                "        if success and success2:\n",
                "            print(f\"üìç Current: {branch.strip()} @ {commit_hash.strip()}\")\n",
                "        \n",
                "        # Show recent commits\n",
                "        success, log_output, _ = run_command(\"git log --oneline -3\")\n",
                "        if success:\n",
                "            print(f\"üìã Recent commits:\")\n",
                "            for line in log_output.strip().split('\\n')[:3]:\n",
                "                if line.strip():\n",
                "                    print(f\"   ‚Ä¢ {line.strip()}\")\n",
                "    \n",
                "    print(f\"üìÅ Working directory: {os.getcwd()}\")\n",
                "    print(\"üéØ Ready to run the NER benchmark notebook!\")\n",
                "\n",
                "else:\n",
                "    print(\"üíª Running locally - skipping git operations\")\n",
                "    print(\"üí° Make sure you've pulled the latest changes manually if needed\")\n",
                "\n",
                "print(\"=\" * 60)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# üîÑ Pull Latest Changes from GitHub (Colab Setup)\n",
                "import os\n",
                "import subprocess\n",
                "\n",
                "def run_command(cmd):\n",
                "    \"\"\"Run shell command and return output\"\"\"\n",
                "    try:\n",
                "        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
                "        return result.returncode == 0, result.stdout, result.stderr\n",
                "    except Exception as e:\n",
                "        return False, \"\", str(e)\n",
                "\n",
                "print(\"üöÄ Setting up latest version from GitHub...\")\n",
                "\n",
                "# Repository details\n",
                "REPO_URL = \"https://github.com/shubhamhackz/ner_benchmark.git\"\n",
                "REPO_NAME = \"ner_benchmark\"\n",
                "\n",
                "# Check if we're in Colab\n",
                "try:\n",
                "    import google.colab\n",
                "    IN_COLAB = True\n",
                "    print(\"üìç Running in Google Colab\")\n",
                "except ImportError:\n",
                "    IN_COLAB = False\n",
                "    print(\"üìç Running locally\")\n",
                "\n",
                "if IN_COLAB:\n",
                "    # Change to content directory in Colab\n",
                "    os.chdir('/content')\n",
                "    \n",
                "    # Check if repository already exists\n",
                "    if os.path.exists(REPO_NAME):\n",
                "        print(f\"üìÇ Repository '{REPO_NAME}' found - pulling latest changes...\")\n",
                "        os.chdir(REPO_NAME)\n",
                "        \n",
                "        # Pull latest changes\n",
                "        success, stdout, stderr = run_command(\"git pull origin main\")\n",
                "        if success:\n",
                "            print(\"‚úÖ Successfully pulled latest changes!\")\n",
                "            if stdout.strip():\n",
                "                print(f\"üìÑ Git output: {stdout.strip()}\")\n",
                "        else:\n",
                "            print(f\"‚ö†Ô∏è Pull failed: {stderr}\")\n",
                "            print(\"üîÑ Trying to reset and pull again...\")\n",
                "            run_command(\"git reset --hard HEAD\")\n",
                "            success, stdout, stderr = run_command(\"git pull origin main\")\n",
                "            if success:\n",
                "                print(\"‚úÖ Successfully pulled after reset!\")\n",
                "            else:\n",
                "                print(f\"‚ùå Still failed: {stderr}\")\n",
                "    else:\n",
                "        print(f\"üì• Cloning repository '{REPO_NAME}'...\")\n",
                "        success, stdout, stderr = run_command(f\"git clone {REPO_URL}\")\n",
                "        if success:\n",
                "            print(\"‚úÖ Successfully cloned repository!\")\n",
                "            os.chdir(REPO_NAME)\n",
                "        else:\n",
                "            print(f\"‚ùå Clone failed: {stderr}\")\n",
                "    \n",
                "    # Show current status\n",
                "    if os.path.exists('.git'):\n",
                "        success, commit_hash, _ = run_command(\"git rev-parse --short HEAD\")\n",
                "        success2, branch, _ = run_command(\"git rev-parse --abbrev-ref HEAD\")\n",
                "        \n",
                "        if success and success2:\n",
                "            print(f\"üìç Current: {branch.strip()} @ {commit_hash.strip()}\")\n",
                "        \n",
                "        # Show recent commits\n",
                "        success, log_output, _ = run_command(\"git log --oneline -3\")\n",
                "        if success:\n",
                "            print(f\"üìã Recent commits:\")\n",
                "            for line in log_output.strip().split('\\n')[:3]:\n",
                "                if line.strip():\n",
                "                    print(f\"   ‚Ä¢ {line.strip()}\")\n",
                "    \n",
                "    print(f\"üìÅ Working directory: {os.getcwd()}\")\n",
                "    print(\"üéØ Ready to run the NER benchmark notebook!\")\n",
                "\n",
                "else:\n",
                "    print(\"üíª Running locally - skipping git operations\")\n",
                "    print(\"üí° Make sure you've pulled the latest changes manually if needed\")\n",
                "\n",
                "print(\"=\" * 60)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# üß™ Quick Test\n",
                "print(\"üß™ Running quick test...\")\n",
                "\n",
                "test_sample = generator.create_clean_sample(0)\n",
                "test_text = \"\\n\".join(test_sample.ocr_lines)\n",
                "\n",
                "print(\"üìù Test Sample:\")\n",
                "print(test_text)\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "\n",
                "# Test GLiNER\n",
                "print(\"\\nü§ñ GLiNER Large Results:\")\n",
                "gliner_results, gliner_time = benchmark.extract_with_gliner(test_text)\n",
                "for entity_type, entities in gliner_results.items():\n",
                "    if entities:\n",
                "        print(f\"  {entity_type}: {entities}\")\n",
                "print(f\"‚è±Ô∏è Time: {gliner_time:.4f}s\")\n",
                "\n",
                "# Test OpenAI if enabled\n",
                "if RUN_OPENAI:\n",
                "    print(\"\\nüî• OpenAI Results:\")\n",
                "    openai_results, openai_time = benchmark.extract_with_openai(test_text)\n",
                "    for entity_type, entities in openai_results.items():\n",
                "        if entities:\n",
                "            print(f\"  {entity_type}: {entities}\")\n",
                "    print(f\"‚è±Ô∏è Time: {openai_time:.4f}s\")\n",
                "    \n",
                "    if gliner_time > 0:\n",
                "        print(f\"\\n‚ö° Speed: GLiNER is {openai_time/gliner_time:.1f}x faster\")\n",
                "\n",
                "print(\"\\n‚úÖ Ground Truth:\")\n",
                "print(f\"  Name: {test_sample.ground_truth.name}\")\n",
                "print(f\"  Company: {test_sample.ground_truth.company}\")\n",
                "print(f\"  Email: {test_sample.ground_truth.email}\")\n",
                "print(f\"  Phone: {test_sample.ground_truth.phone}\")\n",
                "\n",
                "print(\"\\n‚úÖ Quick test completed!\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# üìä Generate Dataset and Run Benchmark\n",
                "print(f\"üìä Generating {SAMPLE_SIZE} test samples...\")\n",
                "test_samples = generator.generate_dataset(SAMPLE_SIZE)\n",
                "\n",
                "print(f\"‚úÖ Generated {len(test_samples)} test samples\")\n",
                "scenario_counts = Counter(sample.scenario for sample in test_samples)\n",
                "print(f\"   üìä Scenarios: {dict(scenario_counts)}\")\n",
                "\n",
                "# Run benchmark\n",
                "print(f\"\\nüöÄ Running benchmark on {len(test_samples)} samples...\")\n",
                "results = []\n",
                "\n",
                "for i, sample in enumerate(test_samples):\n",
                "    if (i + 1) % 50 == 0 or i == 0:\n",
                "        print(f\"   üìà Progress: {i + 1}/{len(test_samples)} samples\")\n",
                "    \n",
                "    text = \"\\n\".join(sample.ocr_lines)\n",
                "    \n",
                "    # GLiNER extraction\n",
                "    gliner_predictions, gliner_time = benchmark.extract_with_gliner(text)\n",
                "    gliner_accuracy = benchmark.calculate_accuracy(gliner_predictions, sample.ground_truth)\n",
                "    \n",
                "    # OpenAI extraction (if enabled)\n",
                "    if RUN_OPENAI:\n",
                "        openai_predictions, openai_time = benchmark.extract_with_openai(text)\n",
                "        openai_accuracy = benchmark.calculate_accuracy(openai_predictions, sample.ground_truth)\n",
                "    else:\n",
                "        openai_accuracy = {label: 0.0 for label in ENTITY_LABELS}\n",
                "        openai_time = 0.0\n",
                "    \n",
                "    # Store results\n",
                "    result = BenchmarkResult(\n",
                "        sample_id=sample.sample_id,\n",
                "        scenario=sample.scenario,\n",
                "        gliner_accuracy=gliner_accuracy,\n",
                "        openai_accuracy=openai_accuracy,\n",
                "        gliner_time=gliner_time,\n",
                "        openai_time=openai_time\n",
                "    )\n",
                "    results.append(result)\n",
                "\n",
                "print(f\"\\n‚úÖ Benchmark completed! Processed {len(results)} samples\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# üìà FINAL BENCHMARK RESULTS ANALYSIS\n",
                "print(\"üî• BENCHMARK RESULTS ANALYSIS\")\n",
                "print(\"=\" * 80)\n",
                "\n",
                "# Convert to DataFrame for analysis\n",
                "data = []\n",
                "for r in results:\n",
                "    for entity_type in ENTITY_LABELS:\n",
                "        data.append({\n",
                "            'sample_id': r.sample_id,\n",
                "            'scenario': r.scenario,\n",
                "            'entity_type': entity_type,\n",
                "            'gliner_accuracy': r.gliner_accuracy.get(entity_type, 0),\n",
                "            'openai_accuracy': r.openai_accuracy.get(entity_type, 0),\n",
                "            'gliner_time': r.gliner_time,\n",
                "            'openai_time': r.openai_time\n",
                "        })\n",
                "\n",
                "df = pd.DataFrame(data)\n",
                "print(f\"üìä Analysis dataset: {len(df)} rows\")\n",
                "\n",
                "# Overall Performance\n",
                "print(\"\\nüèÜ OVERALL PERFORMANCE:\")\n",
                "gliner_overall = df['gliner_accuracy'].mean()\n",
                "avg_gliner_time = df['gliner_time'].mean()\n",
                "\n",
                "print(f\"   ü§ñ GLiNER Large: {gliner_overall:.3f} accuracy, {avg_gliner_time:.4f}s per sample\")\n",
                "\n",
                "if RUN_OPENAI:\n",
                "    openai_overall = df['openai_accuracy'].mean()\n",
                "    avg_openai_time = df['openai_time'].mean()\n",
                "    print(f\"   üî• OpenAI: {openai_overall:.3f} accuracy, {avg_openai_time:.4f}s per sample\")\n",
                "    \n",
                "    # Winner determination\n",
                "    if gliner_overall > openai_overall:\n",
                "        diff = gliner_overall - openai_overall\n",
                "        print(f\"   üèÜ WINNER: GLiNER Large (+{diff:.3f} accuracy advantage)\")\n",
                "    elif openai_overall > gliner_overall:\n",
                "        diff = openai_overall - gliner_overall\n",
                "        print(f\"   üèÜ WINNER: OpenAI (+{diff:.3f} accuracy advantage)\")\n",
                "    else:\n",
                "        print(f\"   ü§ù TIE: Both models perform equally\")\n",
                "\n",
                "# Performance by Entity Type\n",
                "print(\"\\nüìä PERFORMANCE BY ENTITY TYPE:\")\n",
                "entity_performance = df.groupby('entity_type')[['gliner_accuracy', 'openai_accuracy']].mean()\n",
                "\n",
                "for entity in ENTITY_LABELS:\n",
                "    gliner_acc = entity_performance.loc[entity, 'gliner_accuracy']\n",
                "    status = \"üî¥\" if gliner_acc < 0.5 else \"üü°\" if gliner_acc < 0.7 else \"üü¢\" if gliner_acc < 0.9 else \"‚úÖ\"\n",
                "    \n",
                "    print(f\"   {entity:12}: GLiNER {gliner_acc:.3f} {status}\", end=\"\")\n",
                "    \n",
                "    if RUN_OPENAI:\n",
                "        openai_acc = entity_performance.loc[entity, 'openai_accuracy']\n",
                "        openai_status = \"üî¥\" if openai_acc < 0.5 else \"üü°\" if openai_acc < 0.7 else \"üü¢\" if openai_acc < 0.9 else \"‚úÖ\"\n",
                "        winner = \"GLiNER\" if gliner_acc > openai_acc else \"OpenAI\" if openai_acc > gliner_acc else \"Tie\"\n",
                "        print(f\" | OpenAI {openai_acc:.3f} {openai_status} | Winner: {winner}\")\n",
                "    else:\n",
                "        print()\n",
                "\n",
                "# Performance by Scenario\n",
                "print(\"\\nüé≠ PERFORMANCE BY SCENARIO:\")\n",
                "scenario_performance = df.groupby('scenario')[['gliner_accuracy', 'openai_accuracy']].mean()\n",
                "\n",
                "for scenario in scenario_performance.index:\n",
                "    gliner_acc = scenario_performance.loc[scenario, 'gliner_accuracy']\n",
                "    print(f\"   {scenario:8}: GLiNER {gliner_acc:.3f}\", end=\"\")\n",
                "    \n",
                "    if RUN_OPENAI:\n",
                "        openai_acc = scenario_performance.loc[scenario, 'openai_accuracy']\n",
                "        print(f\" | OpenAI {openai_acc:.3f}\")\n",
                "    else:\n",
                "        print()\n",
                "\n",
                "# Speed Analysis\n",
                "print(\"\\n‚ö° SPEED ANALYSIS:\")\n",
                "total_gliner_time = df['gliner_time'].sum()\n",
                "throughput_gliner = len(results) / total_gliner_time if total_gliner_time > 0 else 0\n",
                "\n",
                "print(f\"   ü§ñ GLiNER Large: {throughput_gliner:.1f} samples/second\")\n",
                "\n",
                "if RUN_OPENAI:\n",
                "    total_openai_time = df['openai_time'].sum()\n",
                "    throughput_openai = len(results) / total_openai_time if total_openai_time > 0 else 0\n",
                "    \n",
                "    print(f\"   üî• OpenAI: {throughput_openai:.1f} samples/second\")\n",
                "    \n",
                "    if throughput_openai > 0:\n",
                "        speedup = throughput_gliner / throughput_openai\n",
                "        print(f\"   üìà GLiNER is {speedup:.1f}x faster than OpenAI\")\n",
                "\n",
                "# Cost Analysis (if OpenAI enabled)\n",
                "if RUN_OPENAI:\n",
                "    print(\"\\nüí∞ COST ANALYSIS (per 1000 samples):\")\n",
                "    \n",
                "    # Rough OpenAI cost estimate\n",
                "    openai_cost_1000 = 0.15  # Approximate cost for GPT-4o-mini\n",
                "    gliner_cost_1000 = 0.0   # Free local model\n",
                "    \n",
                "    print(f\"   ü§ñ GLiNER Large: $0.00 (FREE)\")\n",
                "    print(f\"   üî• OpenAI: ~${openai_cost_1000:.2f}\")\n",
                "    print(f\"   üí° GLiNER saves ~${openai_cost_1000:.2f} per 1000 samples\")\n",
                "\n",
                "# üìä VISUAL BENCHMARK CHARTS\n",
                "print(\"\\n\" + \"=\" * 80)\n",
                "print(\"üìä VISUAL BENCHMARK CHARTS\")\n",
                "print(\"=\" * 80)\n",
                "\n",
                "# Set up the plotting style\n",
                "plt.style.use('default')\n",
                "plt.rcParams['figure.figsize'] = (15, 12)\n",
                "plt.rcParams['font.size'] = 10\n",
                "\n",
                "if RUN_OPENAI:\n",
                "    # Create comprehensive comparison charts\n",
                "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
                "    fig.suptitle('üî• GLiNER vs OpenAI Benchmark Results', fontsize=16, fontweight='bold')\n",
                "    \n",
                "    # 1. Overall Accuracy Comparison\n",
                "    models = ['GLiNER Large', 'OpenAI GPT-4o-mini']\n",
                "    accuracies = [gliner_overall, openai_overall]\n",
                "    colors = ['#2E8B57', '#FF6B35']\n",
                "    \n",
                "    bars1 = ax1.bar(models, accuracies, color=colors, alpha=0.8, edgecolor='black', linewidth=1)\n",
                "    ax1.set_title('üèÜ Overall Accuracy Comparison', fontweight='bold', pad=20)\n",
                "    ax1.set_ylabel('Accuracy Score')\n",
                "    ax1.set_ylim(0, 1)\n",
                "    ax1.grid(axis='y', alpha=0.3)\n",
                "    \n",
                "    # Add value labels on bars\n",
                "    for bar, acc in zip(bars1, accuracies):\n",
                "        height = bar.get_height()\n",
                "        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
                "                f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')\n",
                "    \n",
                "    # 2. Entity Type Performance\n",
                "    entities = entity_performance.index\n",
                "    gliner_accs = entity_performance['gliner_accuracy'].values\n",
                "    openai_accs = entity_performance['openai_accuracy'].values\n",
                "    \n",
                "    x = np.arange(len(entities))\n",
                "    width = 0.35\n",
                "    \n",
                "    bars2 = ax2.bar(x - width/2, gliner_accs, width, label='GLiNER Large', \n",
                "                    color='#2E8B57', alpha=0.8, edgecolor='black', linewidth=1)\n",
                "    bars3 = ax2.bar(x + width/2, openai_accs, width, label='OpenAI GPT-4o-mini', \n",
                "                    color='#FF6B35', alpha=0.8, edgecolor='black', linewidth=1)\n",
                "    \n",
                "    ax2.set_title('üìä Performance by Entity Type', fontweight='bold', pad=20)\n",
                "    ax2.set_ylabel('Accuracy Score')\n",
                "    ax2.set_xlabel('Entity Types')\n",
                "    ax2.set_xticks(x)\n",
                "    ax2.set_xticklabels(entities, rotation=45)\n",
                "    ax2.legend()\n",
                "    ax2.grid(axis='y', alpha=0.3)\n",
                "    ax2.set_ylim(0, 1)\n",
                "    \n",
                "    # Add value labels\n",
                "    for bars in [bars2, bars3]:\n",
                "        for bar in bars:\n",
                "            height = bar.get_height()\n",
                "            ax2.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
                "                    f'{height:.2f}', ha='center', va='bottom', fontsize=8)\n",
                "    \n",
                "    # 3. Speed Comparison\n",
                "    speeds = [throughput_gliner, throughput_openai]\n",
                "    bars4 = ax3.bar(models, speeds, color=colors, alpha=0.8, edgecolor='black', linewidth=1)\n",
                "    ax3.set_title('‚ö° Speed Comparison (Samples/Second)', fontweight='bold', pad=20)\n",
                "    ax3.set_ylabel('Throughput (samples/sec)')\n",
                "    ax3.grid(axis='y', alpha=0.3)\n",
                "    \n",
                "    for bar, speed in zip(bars4, speeds):\n",
                "        height = bar.get_height()\n",
                "        ax3.text(bar.get_x() + bar.get_width()/2., height * 1.02,\n",
                "                f'{speed:.1f}', ha='center', va='bottom', fontweight='bold')\n",
                "    \n",
                "    # 4. Cost Analysis\n",
                "    costs = [0.0, openai_cost_1000]\n",
                "    bars5 = ax4.bar(models, costs, color=colors, alpha=0.8, edgecolor='black', linewidth=1)\n",
                "    ax4.set_title('üí∞ Cost per 1000 Samples (USD)', fontweight='bold', pad=20)\n",
                "    ax4.set_ylabel('Cost ($)')\n",
                "    ax4.grid(axis='y', alpha=0.3)\n",
                "    \n",
                "    for bar, cost in zip(bars5, costs):\n",
                "        height = bar.get_height()\n",
                "        ax4.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
                "                f'${cost:.2f}', ha='center', va='bottom', fontweight='bold')\n",
                "    \n",
                "else:\n",
                "    # GLiNER-only visualization\n",
                "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
                "    fig.suptitle('ü§ñ GLiNER Large Performance Analysis', fontsize=16, fontweight='bold')\n",
                "    \n",
                "    # 1. Overall Performance\n",
                "    ax1.bar(['GLiNER Large'], [gliner_overall], color='#2E8B57', alpha=0.8, \n",
                "            edgecolor='black', linewidth=1)\n",
                "    ax1.set_title('üèÜ Overall Accuracy', fontweight='bold', pad=20)\n",
                "    ax1.set_ylabel('Accuracy Score')\n",
                "    ax1.set_ylim(0, 1)\n",
                "    ax1.grid(axis='y', alpha=0.3)\n",
                "    ax1.text(0, gliner_overall + 0.02, f'{gliner_overall:.3f}', \n",
                "            ha='center', va='bottom', fontweight='bold')\n",
                "    \n",
                "    # 2. Entity Type Performance\n",
                "    entities = entity_performance.index\n",
                "    gliner_accs = entity_performance['gliner_accuracy'].values\n",
                "    \n",
                "    colors_entities = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']\n",
                "    bars = ax2.bar(entities, gliner_accs, color=colors_entities, alpha=0.8, \n",
                "                  edgecolor='black', linewidth=1)\n",
                "    ax2.set_title('üìä Performance by Entity Type', fontweight='bold', pad=20)\n",
                "    ax2.set_ylabel('Accuracy Score')\n",
                "    ax2.set_xlabel('Entity Types')\n",
                "    ax2.tick_params(axis='x', rotation=45)\n",
                "    ax2.grid(axis='y', alpha=0.3)\n",
                "    ax2.set_ylim(0, 1)\n",
                "    \n",
                "    for bar, acc in zip(bars, gliner_accs):\n",
                "        height = bar.get_height()\n",
                "        ax2.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
                "                f'{acc:.2f}', ha='center', va='bottom', fontsize=9)\n",
                "    \n",
                "    # 3. Speed Analysis\n",
                "    ax3.bar(['GLiNER Large'], [throughput_gliner], color='#2E8B57', alpha=0.8,\n",
                "            edgecolor='black', linewidth=1)\n",
                "    ax3.set_title('‚ö° Processing Speed', fontweight='bold', pad=20)\n",
                "    ax3.set_ylabel('Throughput (samples/sec)')\n",
                "    ax3.grid(axis='y', alpha=0.3)\n",
                "    ax3.text(0, throughput_gliner * 1.02, f'{throughput_gliner:.1f}', \n",
                "            ha='center', va='bottom', fontweight='bold')\n",
                "    \n",
                "    # 4. Scenario Performance\n",
                "    scenarios = scenario_performance.index\n",
                "    scenario_accs = scenario_performance['gliner_accuracy'].values\n",
                "    \n",
                "    ax4.bar(scenarios, scenario_accs, color=['#FFB6C1', '#98FB98'], alpha=0.8,\n",
                "            edgecolor='black', linewidth=1)\n",
                "    ax4.set_title('üé≠ Performance by Scenario', fontweight='bold', pad=20)\n",
                "    ax4.set_ylabel('Accuracy Score')\n",
                "    ax4.set_xlabel('Scenarios')\n",
                "    ax4.grid(axis='y', alpha=0.3)\n",
                "    ax4.set_ylim(0, 1)\n",
                "    \n",
                "    for i, (scenario, acc) in enumerate(zip(scenarios, scenario_accs)):\n",
                "        ax4.text(i, acc + 0.01, f'{acc:.2f}', ha='center', va='bottom', fontsize=9)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# Final Recommendation\n",
                "print(\"\\nüéØ FINAL RECOMMENDATION:\")\n",
                "if RUN_OPENAI:\n",
                "    if gliner_overall >= openai_overall * 0.95:  # Within 5%\n",
                "        print(\"   üèÜ RECOMMENDATION: Use GLiNER Large\")\n",
                "        print(\"   üí° Reasons: Comparable accuracy + FREE + Faster + Privacy\")\n",
                "    else:\n",
                "        accuracy_gap = openai_overall - gliner_overall\n",
                "        print(\"   ü§î RECOMMENDATION: Consider your priorities\")\n",
                "        print(f\"   üìä OpenAI has {accuracy_gap:.3f} better accuracy but costs money\")\n",
                "        print(f\"   üí∞ GLiNER is free and faster but {accuracy_gap:.3f} lower accuracy\")\n",
                "else:\n",
                "    print(\"   üèÜ GLiNER Large Performance Summary:\")\n",
                "    print(f\"   üìä Overall Accuracy: {gliner_overall:.3f}\")\n",
                "    print(f\"   ‚ö° Speed: {throughput_gliner:.1f} samples/second\")\n",
                "    print(f\"   üí∞ Cost: FREE\")\n",
                "    print(f\"   üîí Privacy: Complete (local processing)\")\n",
                "\n",
                "print(\"\\n\" + \"=\" * 80)\n",
                "print(\"‚úÖ Benchmark analysis completed!\")\n",
                "print(\"üìä Visual charts displayed above!\")\n",
                "print(\"üöÄ Ready for production deployment!\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# üîÑ Pull Latest Changes from GitHub (Colab Setup)\n",
                "import os\n",
                "import subprocess\n",
                "\n",
                "def run_command(cmd):\n",
                "    \"\"\"Run shell command and return output\"\"\"\n",
                "    try:\n",
                "        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
                "        return result.returncode == 0, result.stdout, result.stderr\n",
                "    except Exception as e:\n",
                "        return False, \"\", str(e)\n",
                "\n",
                "print(\"üöÄ Setting up latest version from GitHub...\")\n",
                "\n",
                "# Repository details\n",
                "REPO_URL = \"https://github.com/shubhamhackz/ner_benchmark.git\"\n",
                "REPO_NAME = \"ner_benchmark\"\n",
                "\n",
                "# Check if we're in Colab\n",
                "try:\n",
                "    import google.colab\n",
                "    IN_COLAB = True\n",
                "    print(\"üìç Running in Google Colab\")\n",
                "except ImportError:\n",
                "    IN_COLAB = False\n",
                "    print(\"üìç Running locally\")\n",
                "\n",
                "if IN_COLAB:\n",
                "    # Change to content directory in Colab\n",
                "    os.chdir('/content')\n",
                "    \n",
                "    # Check if repository already exists\n",
                "    if os.path.exists(REPO_NAME):\n",
                "        print(f\"üìÇ Repository '{REPO_NAME}' found - pulling latest changes...\")\n",
                "        os.chdir(REPO_NAME)\n",
                "        \n",
                "        # Pull latest changes\n",
                "        success, stdout, stderr = run_command(\"git pull origin main\")\n",
                "        if success:\n",
                "            print(\"‚úÖ Successfully pulled latest changes!\")\n",
                "            if stdout.strip():\n",
                "                print(f\"üìÑ Git output: {stdout.strip()}\")\n",
                "        else:\n",
                "            print(f\"‚ö†Ô∏è Pull failed: {stderr}\")\n",
                "            print(\"üîÑ Trying to reset and pull again...\")\n",
                "            run_command(\"git reset --hard HEAD\")\n",
                "            success, stdout, stderr = run_command(\"git pull origin main\")\n",
                "            if success:\n",
                "                print(\"‚úÖ Successfully pulled after reset!\")\n",
                "            else:\n",
                "                print(f\"‚ùå Still failed: {stderr}\")\n",
                "    else:\n",
                "        print(f\"üì• Cloning repository '{REPO_NAME}'...\")\n",
                "        success, stdout, stderr = run_command(f\"git clone {REPO_URL}\")\n",
                "        if success:\n",
                "            print(\"‚úÖ Successfully cloned repository!\")\n",
                "            os.chdir(REPO_NAME)\n",
                "        else:\n",
                "            print(f\"‚ùå Clone failed: {stderr}\")\n",
                "    \n",
                "    # Show current status\n",
                "    if os.path.exists('.git'):\n",
                "        success, commit_hash, _ = run_command(\"git rev-parse --short HEAD\")\n",
                "        success2, branch, _ = run_command(\"git rev-parse --abbrev-ref HEAD\")\n",
                "        \n",
                "        if success and success2:\n",
                "            print(f\"üìç Current: {branch.strip()} @ {commit_hash.strip()}\")\n",
                "        \n",
                "        # Show recent commits\n",
                "        success, log_output, _ = run_command(\"git log --oneline -3\")\n",
                "        if success:\n",
                "            print(f\"üìã Recent commits:\")\n",
                "            for line in log_output.strip().split('\\n')[:3]:\n",
                "                if line.strip():\n",
                "                    print(f\"   ‚Ä¢ {line.strip()}\")\n",
                "    \n",
                "    print(f\"üìÅ Working directory: {os.getcwd()}\")\n",
                "    print(\"üéØ Ready to run the NER benchmark notebook!\")\n",
                "\n",
                "else:\n",
                "    print(\"üíª Running locally - skipping git operations\")\n",
                "    print(\"üí° Make sure you've pulled the latest changes manually if needed\")\n",
                "\n",
                "print(\"=\" * 60)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# üß™ Interactive Entity Extraction Testing\n",
                "print(\"üß™ INTERACTIVE ENTITY EXTRACTION TESTING\")\n",
                "print(\"=\" * 80)\n",
                "print(\"üí° Test the models with your own text!\")\n",
                "print(\"üìù Enter any text and see both GLiNER and OpenAI extract entities\")\n",
                "print(\"üè∑Ô∏è Entities: person, email, phone, organization\")\n",
                "print(\"=\" * 80)\n",
                "\n",
                "def format_extraction_results(results, model_name, extraction_time):\n",
                "    \"\"\"Format and display extraction results beautifully\"\"\"\n",
                "    print(f\"\\nü§ñ {model_name} Results (‚è±Ô∏è {extraction_time:.4f}s):\")\n",
                "    print(\"‚îÄ\" * 50)\n",
                "    \n",
                "    found_entities = False\n",
                "    for entity_type, entities in results.items():\n",
                "        if entities:\n",
                "            found_entities = True\n",
                "            entities_str = \", \".join([f\"'{entity}'\" for entity in entities])\n",
                "            icon = {\"person\": \"üë§\", \"email\": \"üìß\", \"phone\": \"üìû\", \"organization\": \"üè¢\"}.get(entity_type, \"üè∑Ô∏è\")\n",
                "            print(f\"   {icon} {entity_type.title()}: {entities_str}\")\n",
                "    \n",
                "    if not found_entities:\n",
                "        print(\"   ‚ùå No entities found\")\n",
                "\n",
                "def interactive_test():\n",
                "    \"\"\"Run interactive entity extraction test\"\"\"\n",
                "    test_count = 0\n",
                "    \n",
                "    while True:\n",
                "        test_count += 1\n",
                "        print(f\"\\nüîç TEST #{test_count}\")\n",
                "        print(\"‚îÄ\" * 30)\n",
                "        \n",
                "        # Get user input\n",
                "        print(\"üìù Enter text to analyze (or 'quit' to exit):\")\n",
                "        user_text = input(\"‚û§ \").strip()\n",
                "        \n",
                "        if user_text.lower() in ['quit', 'exit', 'q', '']:\n",
                "            print(\"üëã Goodbye! Thanks for testing!\")\n",
                "            break\n",
                "            \n",
                "        if len(user_text) < 3:\n",
                "            print(\"‚ö†Ô∏è Please enter more text (at least 3 characters)\")\n",
                "            continue\n",
                "            \n",
                "        print(f\"\\nüìÑ Input Text:\")\n",
                "        print(f\"   \\\"{user_text}\\\"\")\n",
                "        print(\"\\nüöÄ Extracting entities...\")\n",
                "        \n",
                "        # Extract with GLiNER\n",
                "        try:\n",
                "            gliner_results, gliner_time = benchmark.extract_with_gliner(user_text)\n",
                "            format_extraction_results(gliner_results, \"GLiNER Large\", gliner_time)\n",
                "        except Exception as e:\n",
                "            print(f\"‚ùå GLiNER extraction failed: {e}\")\n",
                "            \n",
                "        # Extract with OpenAI (if enabled)\n",
                "        if RUN_OPENAI:\n",
                "            try:\n",
                "                openai_results, openai_time = benchmark.extract_with_openai(user_text)\n",
                "                format_extraction_results(openai_results, \"OpenAI GPT-4o-mini\", openai_time)\n",
                "                \n",
                "                # Speed comparison\n",
                "                if gliner_time > 0 and openai_time > 0:\n",
                "                    speedup = openai_time / gliner_time\n",
                "                    print(f\"\\n‚ö° Speed: GLiNER is {speedup:.1f}x faster than OpenAI\")\n",
                "                    \n",
                "            except Exception as e:\n",
                "                print(f\"‚ùå OpenAI extraction failed: {e}\")\n",
                "        else:\n",
                "            print(f\"\\nüí° OpenAI comparison disabled - running GLiNER only mode\")\n",
                "            \n",
                "        print(\"\\n\" + \"=\"*50)\n",
                "\n",
                "# Example test cases\n",
                "print(\"\\nüí° Example test cases you can try:\")\n",
                "examples = [\n",
                "    \"Dr. Sarah Johnson from TechCorp Inc. Contact: sarah.j@techcorp.com or +1-555-0123\",\n",
                "    \"Michael Brown, Senior Developer at Innovation Labs. Email: m.brown@innolabs.org Phone: 555-0987\",\n",
                "    \"Contact Lisa Wilson at Future Systems (lisa@future-sys.net) for support. Call 555-1234.\",\n",
                "    \"John Smith works at Global Dynamics. Reach him at john.smith@globaldyn.com or 555-5678\"\n",
                "]\n",
                "\n",
                "for i, example in enumerate(examples, 1):\n",
                "    print(f\"   {i}. {example}\")\n",
                "\n",
                "print(f\"\\nüéØ Choose one of the examples above, or enter your own text!\")\n",
                "\n",
                "# Start interactive testing\n",
                "try:\n",
                "    interactive_test()\n",
                "except KeyboardInterrupt:\n",
                "    print(\"\\n\\nüõë Testing interrupted by user\")\n",
                "except Exception as e:\n",
                "    print(f\"\\n‚ùå Error during interactive testing: {e}\")\n",
                "    print(\"üí° You can still run individual extractions manually using:\")\n",
                "    print(\"   benchmark.extract_with_gliner('your text here')\")\n",
                "    if RUN_OPENAI:\n",
                "        print(\"   benchmark.extract_with_openai('your text here')\")\n",
                "\n",
                "print(\"\\n‚úÖ Interactive testing session completed!\")\n"
            ]
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
